{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f521518-c703-47bd-8a57-4137be2a45f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-07-27 12:31:34.526464: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-27 12:31:35.325172: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753619495.643989    2065 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753619495.738492    2065 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753619496.379656    2065 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753619496.379757    2065 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753619496.379763    2065 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753619496.379768    2065 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-27 12:31:36.462205: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import math, torch, gc\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    default_data_collator\n",
    ")\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForCausalLM\n",
    "# from transformers.models.gpt2.modeling_gpt2 import GPT2LMHeadModel\n",
    "# from transformers.models.gpt2.modeling_gpt2 import GemmaForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb9820e2-8b3b-416b-9037-0aaa9ac5e82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /lambda/nfs/codebase2/tests\n",
      "Current Working Directory: /lambda/nfs/codebase2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# change working directory\n",
    "current_dir = os.getcwd() \n",
    "print(f\"Current Working Directory: {current_dir}\")\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "os.chdir(parent_dir)\n",
    "current_dir = os.getcwd()\n",
    "print(f\"Current Working Directory: {current_dir}\")\n",
    "#We need to be in the main directory that contains tests, models, etc folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0c85e86-d182-4fe4-b2cd-e99e0bc95523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original rows: 136244\n"
     ]
    }
   ],
   "source": [
    "#----------------- load training data ---------------------------------------\n",
    "import random\n",
    "from datasets import load_from_disk\n",
    "lm_ds = load_from_disk(\"./data/gemma_300MB_bs512\")\n",
    "\n",
    "print(\"original rows:\", len(lm_ds))          # e.g. 50 092"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90088a76-78e5-4ef5-993f-a0a894f612e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trimmed rows : 15000\n"
     ]
    }
   ],
   "source": [
    "# choose how many you want to keep\n",
    "KEEP = 15_000                         # keep 10 k blocks\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "\n",
    "# draw KEEP unique indices and select them\n",
    "idx = random.sample(range(len(lm_ds)), KEEP) # random sample, no replacement\n",
    "lm_ds_small = lm_ds.select(idx)              # constant-time view\n",
    "print(\"trimmed rows :\", len(lm_ds_small))    # 10 000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "647b67ad-5989-40d3-ae91-86e8e72a70f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x73f1ddfb85d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ─── hyper-parameters ────────────────────────────────────────────\n",
    "MODEL_NAME = \"gemma2b-it\"\n",
    "MODEL_PATH=\"./models/\"+MODEL_NAME\n",
    "SPAN       = 124           # sliding-window width\n",
    "BATCH      = 8\n",
    "EPOCHS     = 2\n",
    "LR         = 5e-7\n",
    "SEED       = 42\n",
    "DEVICE     = \"cuda\"\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# ─── 1) sliding-window mask builder ──────────────────────────────\n",
    "# from coarse_grain_model import GemmaWithSlidingWindow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c9878bb-d164-4b5e-9a44-88070c7a2339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 3) load tokenizer & dataset ─────────────────────────────────\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_PATH, use_fast=True)\n",
    "tok.pad_token = tok.eos_token\n",
    "tok.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d650e5d4-0a7d-4759-bd25-20e9c1c562de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:04<00:00,  1.43s/it]\n"
     ]
    }
   ],
   "source": [
    "# ─── 4) load & wrap model ────────────────────────────────────────\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    torch_dtype=torch.bfloat16\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a9a389e-c618-4c4e-aabb-89f2436b005f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2065/1944533246.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# ─── 5) define collator that adds labels ──────────────────────────\n",
    "def causal_collator_with_labels(features):\n",
    "    batch = default_data_collator(features)\n",
    "    batch[\"labels\"] = batch[\"input_ids\"].clone()\n",
    "    return batch\n",
    "\n",
    "# ─── 6) prepare Trainer ──────────────────────────────────────────\n",
    "args = TrainingArguments(\n",
    "    output_dir                  = \"./models/\"+MODEL_NAME+\"_nomask2\", #\"_sw\"+str(SPAN),\n",
    "    overwrite_output_dir        = True,\n",
    "    num_train_epochs            = EPOCHS,\n",
    "    per_device_train_batch_size = BATCH,\n",
    "    fp16                        = False,             # FP16 activations + kernel fusions\n",
    "    bf16                        = True,\n",
    "    gradient_checkpointing      = False,            # disable re-compute\n",
    "    learning_rate               = LR,\n",
    "    warmup_ratio                = 0.1,\n",
    "    optim                       = \"paged_adamw_32bit\",\n",
    "    logging_steps               = 500,\n",
    "    save_strategy               = \"epoch\",\n",
    "    report_to                   = \"none\",\n",
    "    seed                        = SEED,\n",
    "    remove_unused_columns       = False,\n",
    "    dataloader_num_workers      = 4,                # parallel data loading\n",
    "    # pin_memory + prefetch inside Trainer by default\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model          = model,\n",
    "    args           = args,\n",
    "    train_dataset  = lm_ds_small,\n",
    "    eval_dataset   = None,\n",
    "    data_collator  = causal_collator_with_labels,\n",
    "    tokenizer      = tok,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "649e11c5-f5c4-4ff8-ac4e-7f0176ca84fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Training Gemma with sliding-window b=124 …\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3750/3750 24:15, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.560300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.436400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>3.354200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.344200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>3.329100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.337900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>3.328600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128/128 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ final PPL ≈ 28.33\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3976"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ─── 7) train & evaluate ─────────────────────────────────────────\n",
    "print(f\"🚀 Training Gemma with sliding-window b={SPAN} …\")\n",
    "trainer.train()\n",
    "\n",
    "with torch.no_grad():\n",
    "    eval_loss = trainer.evaluate(lm_ds_small.select(range(1024)))[\"eval_loss\"]\n",
    "    print(f\"✓ final PPL ≈ {math.exp(eval_loss):.2f}\")\n",
    "\n",
    "# ─── 8) cleanup ─────────────────────────────────────────────────\n",
    "del model, trainer\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25fb653-9556-42d4-a044-31e40bb51fee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
